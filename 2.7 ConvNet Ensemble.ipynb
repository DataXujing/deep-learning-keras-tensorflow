{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "X_train = np.swapaxes(X_train,1,3)\n",
    "X_train = np.swapaxes(X_train,1,2)\n",
    "\n",
    "X_test = np.swapaxes(X_test,1,3)\n",
    "X_test = np.swapaxes(X_test,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# exercise - implement convnet on Cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# tf.python.control_flow_ops = tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 32, 32\n",
    "nb_classes = 10\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols,3)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols,3)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train,nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test,nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 10) (10000, 32, 32, 3) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/deep-learning/lib/python3.5/site-packages/ipykernel/__main__.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"valid\", input_shape=(32, 32, 3...)`\n",
      "/home/ubuntu/anaconda2/envs/deep-learning/lib/python3.5/site-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 43s 856us/step - loss: 1.8419 - acc: 0.3464 - val_loss: 1.6194 - val_acc: 0.4282\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 49s 988us/step - loss: 1.5604 - acc: 0.4497 - val_loss: 1.5005 - val_acc: 0.4708\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 45s 891us/step - loss: 1.4330 - acc: 0.4954 - val_loss: 1.3858 - val_acc: 0.5089\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 50s 999us/step - loss: 1.3275 - acc: 0.5359 - val_loss: 1.4162 - val_acc: 0.4910\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 1.2461 - acc: 0.5669 - val_loss: 1.3340 - val_acc: 0.5444\n",
      "Test score: 1.33403179512\n",
      "Test accuracy: 0.5444\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Convolution2D(32, 3, 3,\n",
    "                    border_mode='valid',\n",
    "                    input_shape=(img_rows, img_cols,3)))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(128))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Dense(nb_classes))\n",
    "model1.add(Activation('softmax'))\n",
    "\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "          optimizer='sgd',\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "model1.fit(X_train, Y_train, batch_size=32, \n",
    "          nb_epoch=5,verbose=1,\n",
    "          validation_data=(X_test, Y_test))\n",
    "\n",
    "\n",
    "#Evaluating the model on the test data    \n",
    "score, accuracy = model1.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/deep-learning/lib/python3.5/site-packages/ipykernel/__main__.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(4, (3, 3), padding=\"valid\", input_shape=(32, 32, 3...)`\n",
      "/home/ubuntu/anaconda2/envs/deep-learning/lib/python3.5/site-packages/ipykernel/__main__.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(4, (3, 3), padding=\"valid\", input_shape=(32, 32, 3...)`\n",
      "/home/ubuntu/anaconda2/envs/deep-learning/lib/python3.5/site-packages/ipykernel/__main__.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(4, (3, 3), padding=\"valid\", input_shape=(32, 32, 3...)`\n",
      "/home/ubuntu/anaconda2/envs/deep-learning/lib/python3.5/site-packages/ipykernel/__main__.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(4, (3, 3), padding=\"valid\", input_shape=(32, 32, 3...)`\n",
      "/home/ubuntu/anaconda2/envs/deep-learning/lib/python3.5/site-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 35s 699us/step - loss: 2.2971 - acc: 0.1314 - val_loss: 2.2731 - val_acc: 0.1772\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 30s 600us/step - loss: 1.9544 - acc: 0.2940 - val_loss: 1.7720 - val_acc: 0.3650\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 29s 584us/step - loss: 1.7020 - acc: 0.3936 - val_loss: 1.6851 - val_acc: 0.4102\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 30s 607us/step - loss: 1.6133 - acc: 0.4274 - val_loss: 1.5809 - val_acc: 0.4375\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 31s 623us/step - loss: 1.5587 - acc: 0.4451 - val_loss: 1.5312 - val_acc: 0.4571\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 32s 649us/step - loss: 1.5213 - acc: 0.4613 - val_loss: 1.5563 - val_acc: 0.4476\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 42s 831us/step - loss: 1.4879 - acc: 0.4706 - val_loss: 1.5803 - val_acc: 0.4401\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 34s 689us/step - loss: 1.4641 - acc: 0.4824 - val_loss: 1.4873 - val_acc: 0.4736\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 37s 747us/step - loss: 1.4394 - acc: 0.4885 - val_loss: 1.4765 - val_acc: 0.4743\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 34s 686us/step - loss: 1.4195 - acc: 0.4971 - val_loss: 1.4641 - val_acc: 0.4732\n",
      "Test score: 1.46407176952\n",
      "Test accuracy: 0.4732\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Convolution2D(4, 3, 3,\n",
    "                    border_mode='valid',\n",
    "                    input_shape=(img_rows, img_cols,3)))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Convolution2D(4, 3, 3,\n",
    "                    border_mode='valid',\n",
    "                    input_shape=(img_rows, img_cols,3)))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(Convolution2D(4, 3, 3,\n",
    "                    border_mode='valid',\n",
    "                    input_shape=(img_rows, img_cols,3)))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Convolution2D(4, 3, 3,\n",
    "                    border_mode='valid',\n",
    "                    input_shape=(img_rows, img_cols,3)))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(128))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dense(nb_classes))\n",
    "model2.add(Activation('softmax'))\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "          optimizer='sgd',\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "model2.fit(X_train, Y_train, batch_size=32, \n",
    "          nb_epoch=10,verbose=1,\n",
    "          validation_data=(X_test, Y_test))\n",
    "\n",
    "\n",
    "#Evaluating the model on the test data    \n",
    "score, accuracy = model2.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/deep-learning/lib/python3.5/site-packages/ipykernel/__main__.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"valid\", input_shape=(32, 32, 3...)`\n",
      "/home/ubuntu/anaconda2/envs/deep-learning/lib/python3.5/site-packages/ipykernel/__main__.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"valid\", input_shape=(32, 32, 3...)`\n",
      "/home/ubuntu/anaconda2/envs/deep-learning/lib/python3.5/site-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 73s 1ms/step - loss: 1.9271 - acc: 0.3004 - val_loss: 1.6572 - val_acc: 0.4038\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 1.5873 - acc: 0.4356 - val_loss: 1.5237 - val_acc: 0.4518\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 1.4654 - acc: 0.4805 - val_loss: 1.4758 - val_acc: 0.4783\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 1.3744 - acc: 0.5114 - val_loss: 1.3695 - val_acc: 0.5117\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 1.2943 - acc: 0.5405 - val_loss: 1.2793 - val_acc: 0.5462\n",
      "Test score: 1.27926792536\n",
      "Test accuracy: 0.5462\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Convolution2D(32, 3, 3,\n",
    "                    border_mode='valid',\n",
    "                    input_shape=(img_rows, img_cols,3)))\n",
    "model3.add(Activation('relu'))\n",
    "\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model3.add(Convolution2D(32, 3, 3,\n",
    "                    border_mode='valid',\n",
    "                    input_shape=(img_rows, img_cols,3)))\n",
    "model3.add(Activation('relu'))\n",
    "\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(128))\n",
    "model3.add(Activation('relu'))\n",
    "\n",
    "model3.add(Dense(128))\n",
    "model3.add(Activation('relu'))\n",
    "\n",
    "model3.add(Dense(nb_classes))\n",
    "model3.add(Activation('softmax'))\n",
    "\n",
    "model3.compile(loss='categorical_crossentropy',\n",
    "          optimizer='sgd',\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "model3.fit(X_train, Y_train, batch_size=32, \n",
    "          nb_epoch=5,verbose=1,\n",
    "          validation_data=(X_test, Y_test))\n",
    "\n",
    "\n",
    "#Evaluating the model on the test data    \n",
    "score, accuracy = model3.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions1 = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions2 = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions3 = model3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56140000000000001"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_avg = predictions1 +  predictions2 + predictions3 \n",
    "(predictions_avg.argmax(axis=1)==y_test.ravel()).sum()/y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56459999999999999"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_avg = predictions1  + predictions3 \n",
    "(predictions_avg.argmax(axis=1)==y_test.ravel()).sum()/y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56520000000000004"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_avg = 2*predictions1 +  predictions2 + 2*predictions3 \n",
    "(predictions_avg.argmax(axis=1)==y_test.ravel()).sum()/y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
